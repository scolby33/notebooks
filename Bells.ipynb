{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "little_bob = 'x18x14'\n",
    "plain_bob_maj = 'x18x18x18x18'\n",
    "steadman_trip = '3.1.7.3.1.3.1.3.7.1.3.1'\n",
    "bristol_max = '-5T-14.5T-5T.36.14-7T.58.16-9T.70.18-18.9T-18-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize_place_iter(place):\n",
    "    current_token = []\n",
    "    state = 'read'\n",
    "    for char in place:\n",
    "        if state == 'read':\n",
    "            if char == '-' or char == 'x':\n",
    "                if current_token:\n",
    "                    state = 'emit_plus'\n",
    "                else:\n",
    "                    current_token.append('-')\n",
    "                    state = 'emit'\n",
    "            elif char == '.':\n",
    "                state = 'emit'\n",
    "            else:\n",
    "                current_token.append(char)\n",
    "        if state == 'emit':\n",
    "            yield ''.join(current_token)\n",
    "            current_token = []\n",
    "            state = 'read'\n",
    "        if state == 'emit_plus':\n",
    "            yield ''.join(current_token)\n",
    "            yield '-'\n",
    "            current_token = []\n",
    "            state = 'read'\n",
    "    if current_token:\n",
    "        yield ''.join(current_token)\n",
    "        \n",
    "def tokenize_place(place):\n",
    "    return list(tokenize_place_iter(place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert tokenize_place(little_bob) == ['-', '18', '-', '14']\n",
    "assert tokenize_place(plain_bob_maj) == ['-', '18', '-', '18', '-', '18', '-', '18']\n",
    "assert tokenize_place(steadman_trip) == ['3', '1', '7', '3', '1', '3', '1', '3', '7', '1', '3', '1']\n",
    "assert tokenize_place(bristol_max) == ['-', '5T', '-', '14', '5T', '-', '5T', '36', '14', '-', '7T', '58', '16', '-', '9T', '70', '18', '-', '18', '9T', '-', '18', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '5T', '-', '14', '5T', '-', '5T', '36', '14', '-', '7T', '58', '16', '-', '9T', '70', '18', '-', '18', '9T', '-', '18', '-']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "[ 2  1  4  3  6  5  8  7 10  9 12 11]\n",
      "[ 1  2  3  4  6  8  5 10  7 12  9 11]\n",
      "[ 2  1  4  3  8  6 10  5 12  7 11  9]\n",
      "[ 2  4  1  3  6  8  5 10  7 12  9 11]\n",
      "[ 4  2  3  1  6  5  8  7 10  9 12 11]\n",
      "[ 2  4  1  3  5  6  7  8  9 10 11 12]\n",
      "[ 4  2  3  1  5  7  6  9  8 11 10 12]\n",
      "[ 2  4  3  5  1  7  9  6 11  8 12 10]\n",
      "[ 2  3  4  5  7  1  6  9  8 11 10 12]\n",
      "[ 3  2  5  4  1  7  9  6 11  8 12 10]\n",
      "[ 2  3  4  5  7  1  9 11  6 12  8 10]\n",
      "[ 3  2  5  4  7  9  1 11 12  6 10  8]\n",
      "[ 3  5  2  7  4  9 11  1  6 12  8 10]\n",
      "[ 5  3  7  2  9  4  1 11 12  6 10  8]\n",
      "[ 3  5  2  7  4  9 11  1 12 10  6  8]\n",
      "[ 5  3  7  2  9  4 11 12  1 10  8  6]\n",
      "[ 5  7  3  9  2 11  4 12 10  1  6  8]\n",
      "[ 7  5  9  3 11  2 12  4  1 10  8  6]\n",
      "[ 7  9  5 11  3 12  2  4 10  1  6  8]\n",
      "[ 9  7 11  5 12  3  4  2 10  6  1  8]\n",
      "[ 7  9  5 11  3 12  2  4  6 10  8  1]\n",
      "[ 7  5  9  3 11  2 12  4 10  6  1  8]\n",
      "[ 5  7  3  9  2 11  4 12  6 10  8  1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'E', 'T', 'A', 'B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L']\n",
    "def token_to_indices(token):\n",
    "    indices = []\n",
    "    for char in token:\n",
    "        indices.append(idx.index(char))\n",
    "    return indices\n",
    "\n",
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0] + 1)\n",
    "\n",
    "def not_indices(full, indices):\n",
    "    all_indices = np.indices(full.shape)\n",
    "    return np.setxor1d(all_indices, indices)\n",
    "\n",
    "bells = np.arange(1, 13)\n",
    "place = tokenize_place(bristol_max)\n",
    "print(place)\n",
    "print(bells)\n",
    "for _ in range(1):\n",
    "    for token in place:\n",
    "        if token == '-':  # swap every pair\n",
    "            bells = np.ravel(np.flip(np.reshape(bells, (-1, 2)), 1))\n",
    "        else:\n",
    "            indices = token_to_indices(token)\n",
    "            ni = not_indices(bells, indices)\n",
    "            runs = consecutive(ni)\n",
    "            for run in runs:\n",
    "                bells[run] = np.ravel(np.flip(np.reshape(bells[run], (-1, 2)), 1))\n",
    "        print(bells)\n",
    "        assert set(bells) == {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
